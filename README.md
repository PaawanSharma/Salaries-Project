[![Code style**: black](https**://img.shields.io/badge/code%20style-black-000000.svg)](https**://github.com/psf/black)# Salaries prediction project in Python## The problemTwo tables of jobs are given, with each row corresponding to a different joband columns corresponding to various features of those jobs. For the trainingset, salaries are also given for each job. The task is to construct a modelthat can predict the salaries for the test set.## Directory structure* **README.md**: this report.* **code/Salaries prediciton.ipynb**: the main script of code, solving theproblem from start to finish.* **code/**: also contains other code scripts used by the main notebook.    * **code/eda/**: scripts used for exploratory data analysis.         * **code/eda/plot.py**: functions used for creating plots in EDA.         * **code/eda/stats.py**: code used for statistical analysis in EDA.    * **code/feature_engineering/encoders.py**: code used for encoding    categorical variables.    * **code/exceptions.py**: contains an exception used by encoding functions.    * **code/model_selection.py**: code used for cross-validation of    algorithms.    * **code/preprocessing.py**: code used for preparing datasets for machine    learning.* **data/**: the data used in this problem.    * **data/train_features.csv**: the jobs of the training set.    * **data/train_salaries.csv**: the true salaries for the training set jobs.    * **data/test_features.csv**: the jobs of the test set.* **cross_val_logs/**: logs recording cross-validations that were performed.    * **cross_val_logs/train_data_cross_val.csv**: cross-validation log for the    training data.    * **cross_val_logs/engineered_train_data_cross_val.csv**: cross-validation    log for the training data after feature engineering had been performed on    it.* **results/**: the best model found. This directory will contain unqiuesubdirectories for each model deployed.    * **results/_model\_subdirectory_/model.joblib**: the saved model which can    be loaded into a Python script using the joblib module.    * **results/_model\_subdirectory_/feature_importances.csv**: feature    importances for the saved model.    * **results/_model\_subdirectory_/predictions.csv**: the model's    predictions for the test set salaries.* **.gitignore**: files to be ignored by git.## Solution processThe entire solution approach is laid out from start to finish in**code/Salaries prediciton.ipynb**. Here I present a summary of the process.### DEFINEI began by understanding and defining the task at hand.### DISCOVER (EDA)After checking to make sure the data were valid and clean and removingsuspcious outliers, I looked at the distribution of the training datasetsalaries and the correlation of each individual feature with salary. I exploredthree possible encoding systems for categorical variables, applied these eachin turn and investigated correlations between all features.After these observations, I created a baseline model and calculated the meansquared error (MSE) for its predictions. I then hypothesised possiblealgorithms I could use for modelling and whether I could engineer any newfeatures.### DEVELOPI began development by running cross-validation for various algorithms on thetraining data. The results are logged in**cross_val_logs/train_data_cross_val.csv** and the top results can be viewedin the jupyter notebook in a more interpretable form.After I had tested all my hypothesised algorithms on the training data, I wasunsatisfied with the MSE scores I was getting and decided to go back andengineer some new features. For this, I wrote a function that would add columnsto the data representing combinations in twos, threes and fours of thecategorical features jobType, degree, major and industry. I then triedcross-validating several algorithms on this new dataframe, with more accurateresults. These results can be found in**cross_val_logs/engineered_train_data_cross_val.csv** and also in the jupyternotebook.The best model I had created got a mean MSE of 354.97 in cross-validation.### DEPLOYI wrote a function that would take the two datasets, engineer new features,apply encoding to categorical variables, train the best model and return themodel along with its predictions and feature importances. This function wouldalso save the model, predictions and feature importances to file (these can befound in the **results/** directory).I ran the function and saved the results to file. I also plotted the featureimportances in the notebook.